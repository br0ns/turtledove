\subsection{Parsers}
\label{sec:design-parsers}

One of the most basic capabilities of Turtledove is to parse a project. A
project is described by one or more ML Basis files and consists of a collection
of source files containing SML code. Thus we need to be able to parse these two
kinds of data.

We use MLton's mllex and mlyacc for that task. At the time of writing those tools are
really the only option there is when working in Standard ML, apart from writing
the parsers from scratch. The shortcomings of mllex and mlyacc is more than
paid for in that we can let us inspire by existing parsers that use those
tools. The MLKit and MLTon compilers contains parsers for both MLB and SML and
SML/NJ contains a SML parser all written using lex and yacc.

We have chosen to mimic the parsers found in MLTon. That is we have copied the
rules of the lexer and the productions of the grammar with very minor
exceptions. The code for each rule and production is our own though.


\subsubsection{Abstract syntax tree}

A major part of a parser is to decide upon a way to represent the data one is
parsing. In this regard we take an unorthodox approach to representing SML.

The structure of the data one wishes to parse is often described by a BNF
grammar, that is also the case for MLB and SML. The most common way to represent
parsed data is then to define a set of mutually recursive datatypes; one for
each category of the BNF (or nonterminal of the grammar). This approach has
several benefits:

\begin{enumerate}
\item It is easy to design the representation. It can be written directly of the
      BNF. Another side effect of this is that the representation is already
      documented.
\item The type system ensures that it is only possible to represent data with a
      structure defined by the BNF. Other invariants like a particular variable
      naming scheme for example can naturally not be ensured by the type
      system. However some type safety is better than none.
\end{enumerate}

However the type safety offered is also a limitation; where ever one wants to
walk through the representation one needs to define a set of mutually recursive
functions, one for each data type. This represents a significant overhead, when
working with the parsed data and various examples are given in \cite{mbp08} of
how this way of representing the AST blows up code vise. Oftentimes one is only
interested in a small selection of tokens when working through a syntax
tree. Consider for example the task of collecting the names of all defined
functions in a SML program.


Another limitation is that ``wrapper constructors'' are often needed. It happens
when a rule of a category is just the name of another category. In other words,
one category is a subset of the other. Take for example the grammar

\setlength{\grammarindent}{3.5em} 
\begin{quote}
  \begin{grammar}
    <a> ::= "A" | <b>

    <b> ::= "B" | "C"
  \end{grammar}
\end{quote}


If we didn't have the type system values of \textit{b} would also be values of
\textit{a}. But we do have a type system and we model values as mutually
recursive datatypes. This means that the type of values of \textit{a} and the
type of values of \textit{b} are distinct, and so we need a \textit{a}
constructor to hold \textit{b} values. A representation could be

\begin{quote}
\begin{verbatim}
datatype a = a_A
           | a_b of b
     and b = b_B
           | b_C
\end{verbatim}
\end{quote}

When we work with more complex grammars, as the one for SML, wrapping values for
the sake of the type system gets quite obtrusive and thus we have chosen to
represent the AST using only one data type. This doesn't give any integrity but
it gives a great deal of flexibility (``code by convention''). Integrity check
seems to be a small ``price to pay'' compared to the extra flexibility and what
seems to be less code to work with the AST.

\subsubsection{Payload}

\fixme[inline, margin=false]{This was some text about the wrap, but it most
  likely doesn't apply anymore.}

Actually the AST is not just a n-ary tree structure of the above mentioned
single data type. Each node in the AST is a \textit{wrap} of a token (the data
type) and a left and right field both of type $\alpha$. These two fields, left
and right, are polymorph such that any manipulations to the AST can transform it
from some $\alpha$ to some $\beta$.

Initially, out of the parser, the left and right fields are integer character
positions of left- and rightmost part of the text representing the token
including any children. This is later changed in the infix resolving to also
contain infix status and environment information, where the environment
information is that just before, in the left part, and the information after
this node, in the right part.

\fixme{give a reference to where all this is explained in detail}

\subsubsection{Representing SML and Rules}


Both the SML and Rule parser will uses the same AST of one combined data type as
argued above, as this will make it much easier
when comparing actual SML code to a scheme in the defined rules and since the
rule grammar is SML with some extensions. 

\subsubsection{Representing MLB}

We take the common approach of mutually recursive datatypes for representing
MLB. There are two reasons for this.

\begin{enumerate}
\item The BNF is quite small. There are only two categories, namely
  \texttt{basdec} and \texttt{basexp}. But one will probably also want to define
  functions for handling lists of \texttt{basdec}s and lists of bindings (pairs
  of identifiers and \texttt{basexp}s). So four mutually recursive functions
  need to be defined for each operation on an MLB representation. This number is
  acceptable.
\item Turtledove will not need to manipulate MLB as the project manager use its
  own representation of projects, and generate MLB from that, we only ever need
  to read MLB files.
\end{enumerate}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../../report"
%%% End: 
